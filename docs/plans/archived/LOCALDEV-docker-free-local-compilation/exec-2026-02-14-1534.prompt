You are implementing an improvement plan. Read the plan spec below and carry out
its Proposed Approach. Work through the Execution Steps checklist if present.
Satisfy all Acceptance Criteria. Work in the directory: /tmp/improve-worktrees/LOCALDEV

## User direction takes absolute precedence

The plan spec may contain a "User direction" blockquote near the top
(starting with "> **User direction**"). This is the user's most recent
instruction and it is ABSOLUTE LAW. It overrides everything else in
the plan — the scope, the approach, the execution steps, the acceptance
criteria. If anything in the plan contradicts the user direction, the
plan is wrong and the user direction is right. Follow it exactly.
Do not rationalize it away, reinterpret it, or treat it as optional.

## Verify before fixing — do not trust the plan's diagnosis

When the plan or user direction reports a problem ("X is failing",
"Y is broken"), you MUST independently verify it before acting:

1. REPRODUCE the reported problem first. Run the relevant code, read
   the actual error output, check the actual state.
2. DIAGNOSE the cause yourself from the evidence. Do NOT assume the
   plan's explanation of WHY something is failing is correct — the plan
   may contain stale analysis or an agent's guess that was wrong.
3. Only THEN fix the actual cause you found.

The plan may say "X is failing because of Y" — but Y may have been
fixed already and the real cause is Z. If you blindly "fix Y" you will
waste time and may introduce regressions. Always start from the actual
symptoms, not the plan's theory.

---BEGIN PLAN SPEC---
LOCALDEV
Created: 2026-02-14 14:54

# Docker-Free Local Compilation Pipeline

> **User direction (2026-02-14 15:27):** Restarting after crash. Focus should be on the *simplest possible approach

**Goal references:** [PURERB](../../goals/PURERB-pure-ruby-runtime.md), [SELFHOST](../../goals/SELFHOST-clean-bootstrap.md)

## Problem Statement

The main compilation scripts ([compile](../../compile) and [compile2](../../compile2)) use Docker for every step. Local compilation scripts ([compile_local](../../compile_local) and [compile2_local](../../compile2_local)) already exist and work but are disconnected from the build system — the Makefile, `run_rubyspec`, and all `make` targets still use the Docker-based `./compile` and `./compile2`.

## Approach

The simplest possible approach: merge the existing `compile_local` logic into `compile` (and `compile2_local` into `compile2`). If `toolchain/32root/` exists, use local toolchain. Otherwise fall back to Docker. Fix the hardcoded GCC 8 path to auto-detect. That's it.

No new setup scripts. No distro detection. No deb extraction. The existing `make fetch-glibc32` or manual package installation (`apt install gcc-multilib libc6-dev-i386`) + existing `fetch-glibc32` already populate the toolchain directory. This plan only unifies the compile scripts.

## Infrastructure Cost

Low. Modify 2 existing files, delete 2 files, minor Makefile/gitignore touch-ups.

## Scope and Deliverables

### 1. Unify `compile` with `compile_local`

Modify [compile](../../compile) to:
- Check if `toolchain/32root/` exists and contains the required files.
- If yes: use the local toolchain path (the logic currently in `compile_local`).
- If no: fall back to Docker (current behavior).
- Auto-detect the host GCC version by globbing for `crtbegin.o` instead of hardcoding GCC 8.

Apply the same to [compile2](../../compile2) / [compile2_local](../../compile2_local).

After unification, delete `compile_local` and `compile2_local`.

### 2. Makefile integration

- Ensure all existing targets continue to work unchanged — they already call `./compile`.
- Add a `setup-toolchain` target that runs `apt install gcc-multilib libc6-dev-i386` then `make fetch-glibc32` (or equivalent), as a convenience.

## Acceptance Criteria

1. `./compile driver.rb -I . -g` succeeds with the local toolchain (no Docker running) and produces a working `out/driver`.
2. `./compile2 driver.rb -I . -g` succeeds with the local toolchain and produces a working `out/driver2`.
3. `make selftest` passes using the unified `./compile` with local toolchain.
4. `make selftest-c` passes using the unified `./compile` and `./compile2` with local toolchain.
5. `./compile` falls back to Docker gracefully when `toolchain/32root/` is missing and Docker is available.
6. `compile_local` and `compile2_local` are deleted.
7. The unified `compile` script auto-detects the host GCC version rather than hardcoding GCC 8.
8. `run_rubyspec` works without modification.

## Implementation Details

### Files to read/modify

- [compile](../../compile) (33 lines) — Currently a pure-Docker script. Must be restructured to conditionally use local toolchain or Docker.
- [compile2](../../compile2) (33 lines) — Same restructuring.
- [compile_local](../../compile_local) (72 lines) — Contains the local toolchain logic to merge into `compile`. Key elements: GCC version path (line 15, hardcoded to GCC 8), toolchain root detection (line 11), required file validation (line 23), link flags (lines 45-66), tgc.o caching (lines 37-43).
- [compile2_local](../../compile2_local) (72 lines) — Same as `compile_local` but uses `out/driver` instead of `ruby driver.rb`. Will be deleted after merge.
- [Makefile](../../Makefile) — Add `setup-toolchain` convenience target.

### Design for the unified compile script

The unified `compile` script should:

1. Keep the existing `dr()` function for Docker mode.
2. Add a check: does `toolchain/32root/` contain `libc.so.6` and `crt1.o`?
3. Auto-detect GCC version by globbing `toolchain/32root/usr/lib/gcc/x86_64-linux-gnu/*/32/crtbegin.o`.
4. If local toolchain is available, use the linking logic from `compile_local` (lines 45-72).
5. If not, fall back to Docker via `dr()`.

The key difference between `compile` and `compile2` is the compilation step: `ruby driver.rb` vs `out/driver`. The linking step is identical.

### Edge cases to preserve

- **tgc.o caching**: The unified script should only recompile `tgc.c` if `out/tgc.o` doesn't exist (matching `compile_local` behavior).
- **`/tmp` volume mount**: Docker `dr()` in `compile` mounts `-v /tmp:/tmp` but `compile2` does not. Preserve this in Docker fallback.
- **`2>&1` redirect**: `compile2` redirects stderr to stdout on line 17. Preserve this difference.

## Execution Steps

1. [ ] Unify `compile` with `compile_local` — Merge the local toolchain logic from [compile_local](../../compile_local) into [compile](../../compile). Add local toolchain detection, GCC version auto-detection via glob, and Docker fallback. Keep the script simple.

2. [ ] Unify `compile2` with `compile2_local` — Same pattern as step 1, but with `out/driver` invocation and `2` output suffix.

3. [ ] Delete `compile_local` and `compile2_local`.

4. [ ] Add `setup-toolchain` Makefile target — A convenience target that documents/runs the package install + `fetch-glibc32` steps.

5. [ ] Test: `make selftest` — Verify end-to-end compilation works with the unified `compile`.

6. [ ] Test: `make selftest-c` — Verify `compile2` works correctly.

7. [ ] Test: Docker fallback — Temporarily rename `toolchain/32root/` and verify `./compile` falls back to Docker mode. Restore afterward.

---
*Status: APPROVED*

---END PLAN SPEC---

A test specification exists at /tmp/improve-worktrees/LOCALDEV/docs/plans/LOCALDEV-docker-free-local-compilation/test.md. Read it — it defines
the automated test suite you MUST write as part of this implementation.

Implement the plan. Do not ask questions — make reasonable choices.

If the plan has an "## Execution Steps" section with a checklist, work through
the steps in order. Check off each step as you complete it.

IMPORTANT: If the plan contains unchecked acceptance criteria with FAIL notes,
a prior execution attempt failed verification. Focus on fixing the FAILed
criteria. Do not redo work that already passed unless it is broken.

Do NOT write to /tmp/improve-worktrees/LOCALDEV/docs/plans/LOCALDEV-docker-free-local-compilation/log.md or to the spec file at /tmp/improve-worktrees/LOCALDEV/docs/plans/LOCALDEV-docker-free-local-compilation/spec.md.
The log and spec are managed by the orchestrator, not by you.
Focus exclusively on implementing the plan in the target project.

IMPORTANT: .cache/ is for regenerable cache data ONLY. NEVER write scripts,
non-deterministic research results, or any content that cannot be wiped and
recreated to .cache/. Scripts go in bin/. Persistent data goes in docs/ or
the target project directory.

## File placement rules — NEVER litter the project root

Do NOT create loose files or directories in the root of /tmp/improve-worktrees/LOCALDEV.
This is a coordination project, not a dumping ground. All files MUST go
in the appropriate subdirectory:
- Scripts → bin/
- Documentation, guides, setup notes → docs/
- Plan artifacts → the plan's own directory under docs/plans/
- Data files for other projects → that project's own directory

If the plan targets a different project (e.g., ACT, compiler, Novelator),
implementation files belong in THAT project's directory, not here.
Desktop/ may only contain links, dashboard fragments, or references.

NEVER create top-level .md files, data files, setup guides, or quickstart
documents in the project root. If you find yourself writing to a path like
`/tmp/improve-worktrees/LOCALDEV/SOMETHING.md` (not inside a subdirectory), STOP — that file
belongs in docs/ or in the target project.

## Overcorrection guard

When implementing changes based on constraints or feedback:
- Change ONLY what is specifically described as wrong. Do not remove working
  functionality that is not mentioned in the feedback.
- Do NOT invent broader constraints than what was stated. "Don't write to X"
  means exactly that — not "don't write anywhere" or "don't create files."
- If a constraint is ambiguous, interpret it NARROWLY (the specific thing
  mentioned), not broadly (everything remotely related).
- Before removing any existing code or functionality, ask: "Was this
  specifically identified as a problem?" If not, leave it alone.

## Automated test suite is a mandatory deliverable

If test.md exists in the plan directory, read it for the test specification.
Your implementation is NOT complete until:

1. You have written the automated test suite (per test.md or covering your changes)
2. The test suite runs and passes WITHOUT network access or live services
3. External dependencies (APIs, databases, services) are mocked/stubbed
4. The test suite covers the SPECIFIC changes you made — not just the happy path
5. Error paths are tested (connection failures, malformed data, missing resources)

If the code is too tightly coupled to external services to mock, you MUST
refactor it first to support dependency injection or a swappable backend.
Needing real data or live services to run tests is a design bug — fix the design.

"Tests pass" is insufficient — the tests must actually exercise your code paths.
If you modified a method, there must be tests for that method's OTHER behaviors
too, not just the new behavior.

## Follow instructions exactly

When the plan or test.md specifies how to invoke a deliverable, use that
EXACT command. Do NOT substitute `ruby bin/X` for `bin/X`. Do NOT invent
alternative invocations.

If you get errors (500s, crashes, unexpected output), they are REAL errors.
Do NOT dismiss them as "expected." Investigate them. If your experience
differs from what the user reported, assume YOUR testing method is wrong —
not the user. Check: did you use the exact command? The exact arguments?

## Dangerous execution: system-level code

If the plan modifies code that interfaces with system-level resources (terminals,
signals, process groups, file descriptors, network sockets, servers), you MUST:
1. Run the full test suite BEFORE making any changes to establish a baseline
2. Run the full test suite AFTER each individual change
3. If tests fail after a change, revert immediately — do NOT layer more changes
   on top of a broken state
4. NEVER launch the modified program directly (e.g. `ruby rsh.rb`, `./server`)
   — only run the test suite. Broken system-level code can crash the user's machine.
5. If the test suite itself interacts with terminal/process control, run it with
   output capture and timeouts to prevent runaway processes.

## Non-interactive execution

You are running NON-INTERACTIVELY. You cannot pause for user confirmation.
If the plan contains instructions like "STOP AFTER THIS", "wait for user
confirmation", or "do not proceed to Phase N without approval", you MUST
still complete your execution — but limit your scope to the FIRST phase only.
Do NOT attempt subsequent phases that require user confirmation gates.
If the plan is structured as Phase 1 → STOP → Phase 2, execute Phase 1 ONLY.

IMPORTANT: Use markdown link format for all file, plan, goal, and project references.
